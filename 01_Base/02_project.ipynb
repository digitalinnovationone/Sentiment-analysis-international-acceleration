{"cells":[{"cell_type":"markdown","metadata":{"id":"dWPgmYF0YWuc"},"source":["## Step 1 - Importing the libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","import zipfile\n","\n","cv2.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%tensorflow_version 2.x\n","import tensorflow\n","tensorflow.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"mbhivnG9Y8Zb"},"source":["## Step 2 - Connecting to Drive and accessing files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10241,"status":"ok","timestamp":1708100315741,"user":{"displayName":"Isadora Ferrão","userId":"13887238938670982449"},"user_tz":360},"id":"GuU-LKcu8Qun"},"outputs":[],"source":["path = \"/content/gdrive/My Drive/DIO/Material.zip\"\n","zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n","zip_object.extractall(\"./\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["base_imgs = 'Material/fer2013.zip'\n","zip_object = zipfile.ZipFile(file = base_imgs, mode = 'r')\n","zip_object.extractall('./')\n","zip_object.close"]},{"cell_type":"markdown","metadata":{"id":"SOISQ9jRaeQ0"},"source":["## Step 3 - Accessing the database with photos of facial expressions\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = pd.read_csv('fer2013/fer2013.csv')\n","data.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","plt.hist(data['emotion'], bins = 30)\n","plt.title('Imagens x emoções')"]},{"cell_type":"markdown","metadata":{"id":"jsUmk_-HbXJo"},"source":["## Step 4 - Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"mEeGAoXUb1z1"},"source":["## Step 5 - Imports from Tensorflow/Keras"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":1173,"status":"ok","timestamp":1708100389077,"user":{"displayName":"Isadora Ferrão","userId":"13887238938670982449"},"user_tz":360},"id":"1Tm00l7YEdK2"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.models import model_from_json"]},{"cell_type":"markdown","metadata":{"id":"YNQB1Vkxm10R"},"source":["## Step 6 - Split into sets for training and validation"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":336,"status":"ok","timestamp":1708100406646,"user":{"displayName":"Isadora Ferrão","userId":"13887238938670982449"},"user_tz":360},"id":"kT5_JlaPGXpq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"0niLQhS8cCXM"},"source":["## Step 7 - Model Architecture (CNN)"]},{"cell_type":"markdown","metadata":{"id":"x0uyRxZCcM56"},"source":["### Model architecture 1\n","\n","Padding same x valid: https://www.corvil.com/kb/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-tensorflow\n","\n","Original implementation: https://medium.com/@birdortyedi_23820/deep-learning-lab-episode-3-fer2013-c38f2e052280\n","\n","Regularizers: https://keras.io/regularizers/\n","\n","Dropout: http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_features = 64\n","num_labels = 7\n","batch_size = 64\n","epochs = 100\n","width, height = 48, 48\n","\n","model = Sequential()\n","\n","model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu',\n","                 input_shape=(width, height, 1), data_format = 'channels_last',\n","                 kernel_regularizer = l2(0.01)))\n","model.add(Conv2D(num_features, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(2*2*2*num_features, kernel_size=(3,3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.5))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(2*2*2*num_features, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(2*2*num_features, activation='relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(2*num_features, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(num_labels, activation = 'softmax'))\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"-4wjf2RydVfI"},"source":["## Step 8 - Compiling the model"]},{"cell_type":"markdown","metadata":{"id":"NJcdjk6NdlU9"},"source":["Parâmetros Adam: https://arxiv.org/abs/1412.6980\n","\n","Artigo Adam: https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n","\n","beta: Exponential decay rate (e.g. 0.9)"]},{"cell_type":"markdown","metadata":{"id":"EjDXOgXeKiNw"},"source":["### Saving the model architecture to a JSON file"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":123,"status":"ok","timestamp":1708100419798,"user":{"displayName":"Isadora Ferrão","userId":"13887238938670982449"},"user_tz":360},"id":"VGDxx9HMY4vR"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZLOT-lBmd2OS"},"source":["## Step 9 - Training the model"]},{"cell_type":"markdown","metadata":{"id":"DqqVAsrTdygt"},"source":["## Generating graph of improvement at each stage of training"]},{"cell_type":"markdown","metadata":{"id":"fOVHCZvEGZb4"},"source":["### Checking model accuracy"]},{"cell_type":"markdown","metadata":{"id":"YHh7NxjOZ2bD"},"source":["## Loading data to generate the confusion matrix"]},{"cell_type":"markdown","metadata":{"id":"0tjZ91OoZ99v"},"source":["## Creating a confusion matrix"]},{"cell_type":"markdown","metadata":{"id":"bfC8RYZmpBFk"},"source":["## Testing the model"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1OWKBaYt0Vi9qKCvOAfN3OUpAD9tiKOcX","timestamp":1708100041177},{"file_id":"1ogKcnWX6Myd80FAl5k677Yru44SSS6af","timestamp":1573265459548}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
